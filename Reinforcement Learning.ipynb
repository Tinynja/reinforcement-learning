{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122a63ce",
   "metadata": {},
   "source": [
    "# Reinforcement Learning: An Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1eb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('NOTEBOOK_NAME=\"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeab862",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_VENV = '.venv'\n",
    "KERNEL_NAME = 'rl'\n",
    "KERNEL_DISPLAY_NAME = 'RL-venv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$KERNEL_VENV\" \"$KERNEL_NAME\" \"$KERNEL_DISPLAY_NAME\"\n",
    "# Create a venv and a kernel for the notebook\n",
    "KERNEL_VENV=$1\n",
    "KERNEL_NAME=$2\n",
    "KERNEL_DISPLAY_NAME=$3\n",
    "\n",
    "if [ \"$(. \"$KERNEL_VENV/bin/activate\" 2> /dev/null && which python)\" != \"$(pwd)/$KERNEL_VENV/bin/python\" ]; then\n",
    "    python -m venv \"$KERNEL_VENV\" --prompt \"$KERNEL_DISPLAY_NAME\" --system-site-packages;\n",
    "    echo \"Created virtual environment: '$(pwd)/$KERNEL_VENV'\"\n",
    "    OUTPUT_NOT_EMPTY=1\n",
    "fi\n",
    "\n",
    "if ! jupyter kernelspec list | grep -q $KERNEL_NAME; then\n",
    "    (. \"$KERNEL_VENV/bin/activate\"; python -m ipykernel install --user --name=$KERNEL_NAME --display-name=\"$KERNEL_DISPLAY_NAME\")\n",
    "    echo \"## Please refresh page and select: Kernel > Change kernel > $KERNEL_DISPLAY_NAME ##\"\n",
    "    OUTPUT_NOT_EMPTY=1\n",
    "fi\n",
    "\n",
    "if [ -z \"$OUTPUT_NOT_EMPTY\" ]; then echo \"No news is good news!\"; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02159a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Reinforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMIT_MESSAGE = input(\"Next commit message: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$NOTEBOOK_NAME\" \"$KERNEL_DISPLAY_NAME\" \"$COMMIT_MESSAGE\"\n",
    "# Create a venv and a kernel for the notebook\n",
    "NOTEBOOK_NAME=$1\n",
    "KERNEL_DISPLAY_NAME=$2\n",
    "COMMIT_MESSAGE=$3\n",
    "\n",
    "SAVED_KERNEL=$(grep -A4 \\\"kernelspec\\\" \"$NOTEBOOK_NAME\" | grep -Po \"(?<=\\\"display_name\\\": \\\")[^,\\\"]+\")\n",
    "if [ \"$SAVED_KERNEL\" = \"$KERNEL_DISPLAY_NAME\" ]; then\n",
    "#     if git checkout develop; then\n",
    "#     else\n",
    "#     fi\n",
    "    echo foo\n",
    "    mkdir -p .backups\n",
    "    cp \"$NOTEBOOK_NAME\" .backups/\n",
    "    python -m nbconvert --clear-output \"$NOTEBOOK_NAME\"\n",
    "    git add \"$NOTEBOOK_NAME\"\n",
    "    git commit -m \"$COMMIT_MESSAGE\"\n",
    "    cp \".backups/$NOTEBOOK_NAME\" ./\n",
    "#     git push\n",
    "else\n",
    "    echo bar\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed -n -e '/\"kernelspec\"/,/'$(printf \"\\x7d\")'/p' *.ipynb | grep \"\\\"name\\\": \\\"{KERNEL_NAME}\\\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input('LOL')\n",
    "%%bash\n",
    "echo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cece79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $(printf '\\x42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! . '{kernel_venv}/bin/activate'; which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcfc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "! jupyter kernelspec list | grep '{x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pypi libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib configs\n",
    "# %config InlineBackend.figure_formats = ['svg']\n",
    "# plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4918093",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('notebook_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $(pwd)/{nb_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__\n",
    "# python -m nbconvert --clear-output .ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faca5f2",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "## 2.3 - The 10-armed Testbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd922979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArmedBandit:\n",
    "    def __init__(self,arms,runs):\n",
    "        self.arms = arms\n",
    "        self.runs = runs\n",
    "        self.runs_range = np.arange(self.runs)\n",
    "        \n",
    "        self.action_values = np.random.normal(0,1,size=(self.arms,self.runs))\n",
    "        self.optimal_action = self.action_values.argmax(axis=0)\n",
    "    \n",
    "    def step(self,action):\n",
    "        return np.random.normal(self.action_values[action,self.runs_range],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71743a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonPolicy:\n",
    "    def __init__(self,actions,runs,epsilon):\n",
    "        self.actions = actions\n",
    "        self.runs = runs\n",
    "        self.runs_arange = np.arange(runs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.action_reward = np.zeros((actions,runs))\n",
    "        self.action_count = np.zeros((actions,runs))\n",
    "        self.prev_action = np.zeros(runs,dtype=int)\n",
    "    \n",
    "    def act(self):\n",
    "        # action_type: 0=random, 1=greedy\n",
    "        action_type = np.random.rand(self.runs) > self.epsilon\n",
    "        \n",
    "        # random actions\n",
    "        self.prev_action[~action_type] = np.random.randint(self.actions,size=sum(~action_type))\n",
    "        # greedy actions: argmax estimate action values via sample average (replace 0 counts by 1 to avoid div0 error)\n",
    "        self.prev_action[action_type] = (self.action_reward[:,action_type] / \\\n",
    "                                         (self.action_count[:,action_type] + (self.action_count[:,action_type] == 0)) \\\n",
    "                                        ).argmax(axis=0)\n",
    "        return self.prev_action\n",
    "    \n",
    "    def update(self,reward):\n",
    "        self.action_reward[self.prev_action,self.runs_arange] += reward\n",
    "        self.action_count[self.prev_action,self.runs_arange] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7817b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyAnalyser:        \n",
    "    def __init__(self,episode_length):\n",
    "        self.episode_length = episode_length\n",
    "        self.labels = []\n",
    "        self.reward_history = np.zeros((0,episode_length))\n",
    "        self.optimal_history = np.zeros((0,episode_length))\n",
    "        \n",
    "    def create(self,label,env,policy):\n",
    "        self.env = env\n",
    "        self.policy = policy\n",
    "        \n",
    "        self.step = 0\n",
    "        self.labels.append(label)\n",
    "        self.reward_history = np.concatenate((self.reward_history,np.zeros((1,self.episode_length))))\n",
    "        self.optimal_history = np.concatenate((self.optimal_history,np.zeros((1,self.episode_length))))\n",
    "        \n",
    "    def log(self,reward):\n",
    "        self.reward_history[-1,self.step] = reward.mean()\n",
    "        self.optimal_history[-1,self.step] = (self.policy.prev_action == self.env.optimal_action).sum()/self.env.runs\n",
    "        self.step += 1\n",
    "    \n",
    "    def plot(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.reward_history.transpose(),label=self.labels,linewidth=0.75)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(self.optimal_history.transpose(),label=self.labels,linewidth=1)\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bandit_episode(env,policy,datalog,episode_length):\n",
    "    for i in range(episode_length):\n",
    "        action = policy.act()\n",
    "        reward = env.step(action)\n",
    "        policy.update(reward)\n",
    "        datalog.log(reward)\n",
    "\n",
    "arms = 10\n",
    "episode_length = 1000\n",
    "runs = 2000\n",
    "epsilon = [0,0.01,0.1]\n",
    "\n",
    "datalog = PolicyAnalyser(episode_length)\n",
    "for eps in epsilon:\n",
    "    env = ArmedBandit(arms,runs)\n",
    "    policy = EpsilonPolicy(arms,runs,eps)\n",
    "    datalog.create(f'eps={eps}',env,policy)\n",
    "    run_bandit_episode(env,policy,datalog,episode_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalog.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8cbd3",
   "metadata": {},
   "source": [
    "## Exercice 2.5 - Nonstationary Bandit Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-stationnary Armed Bandit\n",
    "class NSArmedBandit(ArmedBandit):\n",
    "    # Armed Bandit problem with action values initialised to 0\n",
    "    # and a random walk every step\n",
    "    def __init__(self,action_value_dev,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self._step = super().step\n",
    "        self.action_values = np.zeros((self.arms,self.runs))\n",
    "        self.action_value_dev = action_value_dev\n",
    "        \n",
    "    def step(self,*args,**kwargs):\n",
    "        self.action_values = np.random.normal(self.action_values,self.action_value_dev)\n",
    "        self.optimal_action = self.action_values.argmax(axis=0)\n",
    "        return self._step(*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_walk_std_dev = 0.01\n",
    "\n",
    "datalog = PolicyAnalyser(episode_length)\n",
    "for eps in epsilon:\n",
    "    env = NSArmedBandit(random_walk_std_dev,arms,runs)\n",
    "    policy = EpsilonPolicy(arms,runs,eps)\n",
    "    datalog.create(f'eps={eps}',env,policy)\n",
    "    run_bandit_episode(env,policy,datalog,episode_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalog.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL-venv",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
